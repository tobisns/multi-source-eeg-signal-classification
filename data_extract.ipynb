{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de71e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mne.decoding import CSP\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import moabb\n",
    "from moabb.datasets import BNCI2014_001, Zhou2016, Weibo2014\n",
    "from moabb.evaluations import WithinSessionEvaluation\n",
    "from moabb.paradigms import LeftRightImagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a2cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [Zhou2016(), BNCI2014_001(), Weibo2014()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea318b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionss = []\n",
    "for d in datasets:\n",
    "    sessionss.append(d.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_channels = set()  # Use a set to store unique channel names\n",
    "\n",
    "for sessions in sessionss:\n",
    "    for subject_name, subject_data in sessions.items():\n",
    "        for session_name, session_data in subject_data.items():\n",
    "            for run_name, raw in session_data.items():\n",
    "                unique_channels.update(raw.pick_types(eeg=True).ch_names)  # Add channels to the set\n",
    "                # print(raw.info)\n",
    "\n",
    "# Convert to a sorted list for consistency\n",
    "unique_channels = sorted(unique_channels)\n",
    "print(len(unique_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "# Step 1: Collect all unique event names across datasets dynamically\n",
    "all_event_names = set()\n",
    "for sessions in sessionss:\n",
    "    for subject_data in sessions.values():\n",
    "        for session_data in subject_data.values():\n",
    "            for raw in session_data.values():\n",
    "                _, event_dict = mne.events_from_annotations(raw)\n",
    "                all_event_names.update(event_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define only the desired event names\n",
    "desired_events = [\"feet\", \"left_hand\", \"right_hand\"]\n",
    "# desired_events = [\"left_hand\", \"right_hand\"]\n",
    "\n",
    "# Create standardized label mapping for these events only\n",
    "standardized_labels = {event: idx for idx, event in enumerate(sorted(desired_events))}\n",
    "\n",
    "print(\"Standardized Labels:\", standardized_labels)  # Debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c0500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "X_all0 = []\n",
    "YD_all0 = []\n",
    "padding_masks0 = []\n",
    "\n",
    "channel_to_index = {ch: i for i, ch in enumerate(unique_channels)}  # Map each channel to an index\n",
    "num_channels = len(unique_channels)  # Total unique channels\n",
    "\n",
    "# Assuming `sessionss` is a list of subjects, each containing sessions and runs\n",
    "for dom, sessions in enumerate(sessionss):\n",
    "    subj_idx = 0\n",
    "    for subject_name, subject_data in sessions.items():\n",
    "        sess_idx = 0\n",
    "        for session_name, session_data in subject_data.items():\n",
    "            for run_name, raw in session_data.items():\n",
    "                # Pick only EEG channels directly (no need to copy first)\n",
    "                raw.pick_types(eeg=True)\n",
    "                raw.resample(200)\n",
    "                raw.filter(l_freq=8, h_freq=30, fir_design='firwin')\n",
    "\n",
    "                # Convert annotations to events\n",
    "                events, event_dict = mne.events_from_annotations(raw)\n",
    "                event_id_to_name = {v: k for k, v in event_dict.items()}\n",
    "\n",
    "                # Define epoch time range\n",
    "                tmin, tmax = -0.2, 4\n",
    "\n",
    "                # Create epochs\n",
    "                epochs = mne.Epochs(\n",
    "                    raw, events, event_dict, tmin=tmin, tmax=tmax, baseline=(None, 0),\n",
    "                    preload=False,  # Don't load into memory immediately\n",
    "                    event_repeated='drop'  # Avoid duplicate event errors\n",
    "                )\n",
    "\n",
    "                # Get epoch data and labels\n",
    "                X_raw = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n",
    "                # Normalize each time series in `aligned_X` to [-1,1]\n",
    "                # X_min = np.min(X_raw, axis=2, keepdims=True)\n",
    "                # X_max = np.max(X_raw, axis=2, keepdims=True)\n",
    "                # # Avoid division by zero\n",
    "                # X_range = X_max - X_min\n",
    "                # X_range[X_range == 0] = 1  # Prevent division by zero\n",
    "                # # Normalize to [-1, 1]\n",
    "                # X_raw = 2 * (X_raw - X_min) / X_range - 1\n",
    "\n",
    "                # Z-score normalization: Normalize each epoch's time series\n",
    "                # Calculate mean and std along the time axis for each channel\n",
    "                X_mean = np.mean(X_raw, axis=2, keepdims=True)  # Mean along time axis\n",
    "                X_std = np.std(X_raw, axis=2, keepdims=True)  # Standard deviation along time axis\n",
    "                X_raw = (X_raw - X_mean) / (X_std + 1e-8)  # Z-score normalization (avoid division by zero)\n",
    "\n",
    "                Y = epochs.events[:, -1]  # Event labels\n",
    "                Y_names = [event_id_to_name.get(event, \"unknown\") for event in Y]\n",
    "                Y_standardized = np.array([standardized_labels.get(name, -1) for name in Y_names])\n",
    "                valid_idx = Y_standardized != -1\n",
    "                Y = Y_standardized[valid_idx]\n",
    "                X_raw = X_raw[valid_idx]\n",
    "                current_channels = raw.ch_names  # Current session's channels\n",
    "\n",
    "                # Align channels using NumPy indexing (faster than loops)\n",
    "                aligned_X = np.zeros((X_raw.shape[0], num_channels, X_raw.shape[2]))  # Empty padded array\n",
    "                padding_mask = np.zeros((X_raw.shape[0], num_channels))  # Binary mask for padding\n",
    "\n",
    "                valid_idx = [channel_to_index[ch] for ch in current_channels if ch in channel_to_index]\n",
    "\n",
    "                aligned_X[:, valid_idx, :] = X_raw[:, :len(valid_idx), :]\n",
    "                padding_mask[:, valid_idx] = 1  # Mark real channels as `1`\n",
    "\n",
    "                # Domain label for domain\n",
    "                D = np.full((aligned_X.shape[0], 1), dom)\n",
    "\n",
    "                # Session label for subject\n",
    "                S = np.full((aligned_X.shape[0], 1), subj_idx)\n",
    "\n",
    "                # Session label for session\n",
    "                T = np.full((aligned_X.shape[0], 1), sess_idx)\n",
    "\n",
    "                # ID = np.full((aligned_X.shape[0], 1), dom * 10000 + subj_idx * 100 + sess_idx)\n",
    "                ID = np.full((aligned_X.shape[0], 1), dom * 10000 + subj_idx * 100)\n",
    "\n",
    "\n",
    "                # Stack labels with domain\n",
    "                YD = np.column_stack((Y, D.flatten(), S.flatten(), T.flatten(), ID.flatten()))\n",
    "\n",
    "                # Efficient stacking\n",
    "                if len(X_all0) == 0:\n",
    "                    X_all0 = aligned_X\n",
    "                    YD_all0 = YD\n",
    "                    padding_masks0 = padding_mask\n",
    "                else:\n",
    "                    X_all0 = np.vstack((X_all0, aligned_X))\n",
    "                    YD_all0 = np.vstack((YD_all0, YD))\n",
    "                    padding_masks0 = np.vstack((padding_masks0, padding_mask))\n",
    "            sess_idx += 1\n",
    "        subj_idx += 1\n",
    "    # break\n",
    "# Remap domain labels (column 1 of YD_all0)\n",
    "unique_ids, remapped_ids = np.unique(YD_all0[:, 4], return_inverse=True)\n",
    "YD_all0[:, 4] = remapped_ids  # Replace domain column with remapped values\n",
    "\n",
    "print(X_all0.shape)  # (n_epochs, n_channels, n_times)\n",
    "print(YD_all0.shape)  # (n_epochs, 2)\n",
    "print(padding_masks0.shape)  # (n_epochs, n_channels) - Binary mask for padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f4bd1",
   "metadata": {},
   "source": [
    "SUBJECT DEPENDENT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac228c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Find indices where domain label (YD[:, 1]) == 0\n",
    "domain0_indices = np.where(((YD_all0[:, 1] == 1) & (YD_all0[:, 3] == 1)) | ((YD_all0[:, 1] == 0) & (YD_all0[:, 3] == 2)))[0]\n",
    "# domain0_indices = np.where(((YD_all0[:, 1] == 0) & (YD_all0[:, 2] == 3)))[0]\n",
    "domain2_indices = np.where(YD_all0[:, 1] == 2)[0]\n",
    "# Step 2: Randomly select 540 indices from those\n",
    "rng = np.random.RandomState(42)\n",
    "domain0_indices = np.union1d(domain0_indices, rng.choice(domain2_indices, size=int(domain2_indices.shape[0]*0.5)))\n",
    "# selected_indices = rng.choice(domain0_indices, size=int(domain0_indices.shape[0]*0.3), replace=False)\n",
    "\n",
    "X_half = X_all0[domain0_indices]\n",
    "YD_half = YD_all0[domain0_indices]\n",
    "padding_masks_half = padding_masks0[domain0_indices]\n",
    "# print(domain0_indices.shape)\n",
    "print(X_half.shape)  # (n_epochs, n_channels, n_times)\n",
    "print(YD_half.shape)  # (n_epochs, 2)\n",
    "print(padding_masks_half.shape)  # (n_epochs, n_channels) - Binary mask for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e4ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Find indices where domain label (YD[:, 1]) == 0\n",
    "# domain1_indices = np.where(((YD_all0[:, 1] == 0) & (YD_all0[:, 3] < 2)) | ((YD_all0[:, 1] == 1) & (YD_all0[:, 3] == 0)) | ((YD_all0[:, 1] == 2) & (YD_all0[:, 2] < 5)))[0]\n",
    "domain1_indices = np.setdiff1d(np.arange(YD_all0.shape[0]), domain0_indices)\n",
    "rng = np.random.RandomState(42)\n",
    "selected_indices = rng.choice(domain1_indices, size=int(domain1_indices.shape[0]*0.7), replace=False)\n",
    "# Get what is NOT in selected_indices\n",
    "# not_selected = np.setdiff1d(domain0_indices, selected_indices)\n",
    "# not_selected = np.where((YD_all0[:, 1] == 0))[0]\n",
    "not_selected = np.setdiff1d(domain1_indices, selected_indices)\n",
    "# not_selected_subset = np.random.choice(not_selected, replace=False)\n",
    "# Step 2: Randomly select 540 indices from those\n",
    "# selected_indices2 = np.random.choice(domain1_indices, size=1260, replace=False)\n",
    "# Union with selected_indices2\n",
    "final_indices = np.union1d(domain1_indices, not_selected)\n",
    "\n",
    "X_val = X_all0[not_selected]\n",
    "YD_val = YD_all0[not_selected]\n",
    "mask_val = padding_masks0[not_selected]\n",
    "\n",
    "\n",
    "X_all = X_all0[selected_indices]          # (8058 - 1185, 60, 1051)\n",
    "YD_all = YD_all0[selected_indices]          # (8058 - 1185, 2)\n",
    "padding_masks = padding_masks0[selected_indices]          # (8058 - 1185, 60)\n",
    "\n",
    "print(X_all.shape)  # (n_epochs, n_channels, n_times)\n",
    "print(YD_all.shape)  # (n_epochs, 2)\n",
    "print(padding_masks.shape)  # (n_epochs, n_channels) - Binary mask for padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd83f7",
   "metadata": {},
   "source": [
    "CROSS-SUBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25c649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Find indices where domain label (YD[:, 1]) == 0\n",
    "domain0_indices = np.where(((YD_all0[:, 1] == 1) & (YD_all0[:, 2] > 5)) | ((YD_all0[:, 1] == 0) & (YD_all0[:, 2] > 2)))[0]\n",
    "# domain0_indices = np.where(((YD_all0[:, 1] == 0) & (YD_all0[:, 2] == 3)))[0]\n",
    "domain2_indices = np.where((YD_all0[:, 1] == 2) & (YD_all0[:, 2] > 6))[0]\n",
    "# Step 2: Randomly select 540 indices from those\n",
    "rng = np.random.RandomState(42)\n",
    "# domain0_indices = np.union1d(domain0_indices, rng.choice(domain2_indices, size=int(domain2_indices.shape[0]*0.5)))\n",
    "domain0_indices = np.union1d(domain0_indices, domain2_indices)\n",
    "# selected_indices = rng.choice(domain0_indices, size=int(domain0_indices.shape[0]*0.3), replace=False)\n",
    "\n",
    "X_half = X_all0[domain0_indices]\n",
    "YD_half = YD_all0[domain0_indices]\n",
    "padding_masks_half = padding_masks0[domain0_indices]\n",
    "# print(domain0_indices.shape)\n",
    "print(X_half.shape)  # (n_epochs, n_channels, n_times)\n",
    "print(YD_half.shape)  # (n_epochs, 2)\n",
    "print(padding_masks_half.shape)  # (n_epochs, n_channels) - Binary mask for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6412d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "domain1_indices = np.where(((YD_all0[:, 1] == 1) & (YD_all0[:, 2] > 3)) | ((YD_all0[:, 1] == 0) & (YD_all0[:, 2] > 1)) | ((YD_all0[:, 1] == 2) & (YD_all0[:, 2] > 4)))[0]\n",
    "\n",
    "not_selected = np.setdiff1d(domain1_indices, domain0_indices)\n",
    "selected_indices = np.setdiff1d(np.arange(YD_all0.shape[0]), domain0_indices)\n",
    "selected_indices = np.setdiff1d(selected_indices, not_selected)\n",
    "\n",
    "final_indices = np.union1d(domain1_indices, not_selected)\n",
    "\n",
    "X_val = X_all0[not_selected]\n",
    "YD_val = YD_all0[not_selected]\n",
    "mask_val = padding_masks0[not_selected]\n",
    "\n",
    "\n",
    "X_all = X_all0[selected_indices]          \n",
    "YD_all = YD_all0[selected_indices]          \n",
    "padding_masks = padding_masks0[selected_indices]\n",
    "\n",
    "print(X_all.shape)  # (n_epochs, n_channels, n_times)\n",
    "print(YD_all.shape)  # (n_epochs, 2)\n",
    "print(padding_masks.shape)  # (n_epochs, n_channels) - Binary mask for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db207025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the 10-20 montage\n",
    "montage_1020 = mne.channels.make_standard_montage('standard_1020')\n",
    "\n",
    "# Extract channel positions\n",
    "channel_positions = {\n",
    "    ch: pos[:2] for ch, pos in montage_1020.get_positions()['ch_pos'].items()  # Extract (x, y) only\n",
    "}\n",
    "\n",
    "# Define number of total channels (27 in your case)\n",
    "num_channels = padding_masks.shape[1]\n",
    "\n",
    "# Initialize an array to store (x, y) locations, defaulting to (0,0) for missing ones\n",
    "channel_xy = np.zeros((num_channels, 2))  # Shape (27, 2)\n",
    "\n",
    "\n",
    "# Assign known positions to their corresponding indices\n",
    "for ch, idx in channel_to_index.items():\n",
    "    if ch in channel_positions:  # Ensure the channel exists in the montage\n",
    "        channel_xy[idx] = channel_positions[ch]\n",
    "\n",
    "print(channel_xy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ef08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_tensor = torch.tensor(X_all, dtype=torch.float32, device=device)\n",
    "YD_tensor = torch.tensor(YD_all, dtype=torch.long, device=device)\n",
    "padding_masks_tensor = torch.tensor(padding_masks, dtype=torch.bool, device=device)\n",
    "channel_xy_tensor = torch.tensor(channel_xy, dtype=torch.float32, device=device)\n",
    "\n",
    "X_tensor_half = torch.tensor(X_val, dtype=torch.float32, device=device)\n",
    "YD_tensor_half = torch.tensor(YD_val, dtype=torch.long, device=device)\n",
    "padding_masks_tensor_half = torch.tensor(mask_val, dtype=torch.bool, device=device)\n",
    "\n",
    "X_tensor_test = torch.tensor(X_half, dtype=torch.float32, device=device)\n",
    "YD_tensor_test = torch.tensor(YD_half, dtype=torch.long, device=device)\n",
    "padding_masks_tensor_test = torch.tensor(padding_masks_half, dtype=torch.bool, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09008ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'X': X_tensor,\n",
    "    'YD': YD_tensor,\n",
    "    'mask': padding_masks_tensor,\n",
    "    'channel_xy': channel_xy_tensor,\n",
    "    'X_val': X_tensor_half,\n",
    "    'YD_val': YD_tensor_half,\n",
    "    'mask_val': padding_masks_tensor_half,\n",
    "    'X_test': X_tensor_test,\n",
    "    'YD_test': YD_tensor_test,\n",
    "    'mask_test': padding_masks_tensor_test\n",
    "}, '/content/drive/MyDrive/eeg_data_TEST.pt')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
